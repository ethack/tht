#!/bin/bash

if [ -n "$DEBUG" ]; then set -x; set -e; fi

print_usage() {
    cat << EOF
Filters Zeek logs based on the search terms with output that can be piped to zeek-cut or other tools that can read Zeek logs.

$(basename "$0") [--<logtype>] [OPTIONS] [search_term] [search_term...] [-- [OPTIONS]]

    Specify one or more [search_terms] to search either STDIN or log files. If you don't specify any search terms, all lines will be printed.

    --<logtype>         is used to search logs of "logtype" (e.g. conn, dns, etc) in the current directory tree (default: conn)
    -|--stdin           reads filenames to search from stdin instead
    -d|--dir <dirglob>  will search logs in <dirglob> instead of current directory
    --no-cache          do not use or store a cache of the results
    
    Lines must match all search terms by default.
    --or       at least one search term is required to appear in a line (as opposed to all terms matching)

    Search terms will match on word boundaries by default.
    -r|--regex               signifies that [search_term(s)] should be treated as regexes
    -s|--starts-with         anchor search term to beginning of field (e.g. 192.168)
    -e|--ends-with           anchor search term to end of field (e.g. google.com)
    -i|--ignore-case         perform case-insensitive matching
    -l|--files-with-matches  print filenames instead of matches
    -o|--only-matching       print only the matching part of lines
    -v|--invert-match        will invert the matching

    -n|--dry-run       print out the final search command rather than execute it

    You can specify search terms in other ways as well.
    -f|--file <patternfile.txt>   file containing newline separated search terms
    -p|--preset <preset>          use a common preset regex with current options being:
                rfc1918           private IPv4 addresses defined in RFC1918
                ipv4              IPv4 addresses
                ipv6              IPv6 addresses
                linklocal         169.254.0.0/16, ffe80::/10

    Any arguments given after -- will be passed to the underlying search command.

Examples:
    $(basename "$0") 10.0.0.1                            conn entries from the current directory tree that match the IP
    $(basename "$0") 10.0.0.1 1.1.1.1                    conn entries from the current directory tree that match the pair of IPs
    $(basename "$0") --or 8.8.8.8 1.1.1.1                conn entries from the current directory tree that match either of IPs
    cat conn.log | $(basename "$0") 10.0.0.1             conn entries from STDIN that match the IP
    $(basename "$0") --dns 'google.com'                  dns entries from the current directory tree that match the domain or any subdomains
    $(basename "$0") --dns --regex '\tgoogle\.com\t'     dns entries from the current directory tree that match the regex

EOF
}

error() {
    >&2 printf "ERROR: %s\n" "$*"
}

exists() {
    command -v "$1" >/dev/null 2>&1
}

isEmpty() {
    # -z return true if unset or set to the empty string
    [ -z "$1" ]
}

isNotEmpty() {
    # -n return true if set to a non-empty string
    [ -n "$1" ]
}

isStdinRedir() {
    # -t returns true if file descriptor (stdin) is a tty,
    # which means it is connected to the terminal;
    # the opposite is if it is redirected or piped
    [ ! -t 0 ]
}

isStdoutRedir() {
    # -t returns true if file descriptor (stdout) is a tty,
    # which means it is connected to the terminal;
    # the opposite is if it is redirected or piped
    [ ! -t 1 ]
}

escapeTerm() {
    term="$1"
    prefix="$2"
    suffix="$3"
    # escape periods and put in word boundaries
    echo -n "$term" | sed 's/\./\\./g' | xargs -0 -n 1 printf "${prefix}%s${suffix}"
}

# defaults
logType=
extra_args=()
escape=true
condition="and"
dryRun=false
invert=false
onlyFilenames=false
grepCmd=ug
termPrefix='\\b'
termSuffix='\\b'
terms=()
regexes=()
searchDir=.
logFiles=
zipFiles=
# default to reading from stdin
files=
findFiles=true
# this should be on a ramfs/tmpfs like /tmp
cacheDir=/tmp
useCache=
cacheExpiry="+15" # in minutes

# process command args
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            print_usage
            exit
        ;;
        -s|--starts-with)        termPrefix='[,"\\t]' ;;
        -e|--ends-with)          termSuffix='[,"\\t]' ;;
        -r|--regex)              escape=false ;;
        --or)                    condition="or" ;;
        -n|--dry-run)            dryRun=true ;;
        -v|--invert-match)       invert=true ;;
        -i|--ignore-case)        extra_args+=(--ignore-case) ;;
        -l|--files-with-matches) 
            extra_args+=(--files-with-matches) 
            onlyFilenames=true
        ;;
        -o|--only-matching)      extra_args+=(--only-matching) ;;
        --no-cache)              useCache=false ;;
        -f|--file)
            shift
            patternfile="$1"
            if [ ! -r "$patternfile" ]; then
                error "Cannot read patternfile '$patternfile'"
            else
                # load all lines from file as search terms
                # https://stackoverflow.com/a/1521498
                while IFS= read -r pattern || isNotEmpty "$pattern"; do
                    # skip empty lines (we don't want grep's behavior of matching all on an empty line)
                    if isEmpty "$pattern"; then
                        continue
                    fi
                    terms+=("$pattern")
                done < "$patternfile"
            fi
        ;;
        -p|--preset)
            shift
            # add any specified preset regexes
            case $1 in
            rfc1918)    regexes+=('\b(10\.[0-9]{1,3}|172\.1[6-9]|172\.2[0-9]|172\.3[0-1]|192\.168)\.[0-9]{1,3}\.[0-9]{1,3}\b') ;;
            ipv4)       regexes+=('\b((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\.)){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))\b') ;;
                        # https://stackoverflow.com/a/17871737
            ipv6)       regexes+=('\b(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\b') ;;
                        # 169.254.0.0/16, ffe80::/10
            linklocal)  regexes+=('\b(169\.254\.([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(fe80:(:[0-9a-fA-F]{0,4}){0,4}(%[0-9a-zA-Z]{1,}){0,1})\b') ;;
            esac
        ;;
        -d|--dir)
            shift
            searchDir="$1"
        ;;
        -|--stdin)
            findFiles=false
            files=()
            # search files passed on stdin
            # TODO will this work if they aren't newline separated?
            while IFS= read -r file; do
                files+=("$file")
                if [[ $file = *.gz ]]; then
                    zipFiles+=("$file")
                else
                    logFiles+=("$file")
                fi
            done
        ;;
        --)
            shift
            # pass through args after "--" to search tool
            extra_args+=("$@")
            break
        ;;
        --*)
            # log type e.g. --conn or --dns
            logType="${1#"--"}"
        ;;
        *)
            # the rest of the arguments are search terms
            terms+=("$1")
        ;;
    esac
    shift
done

# FILTER_NO_STDIN is a special environment variable that can be set to force disabling reading from stdin (e.g. fzf)
if $findFiles && (isNotEmpty "$logType" || ! isStdinRedir || isNotEmpty "$FILTER_NO_STDIN"); then
    logType=${logType:-conn}
    # performs brace expansion (e.g. {0..10}) and glob expansion (e.g. conn*)
    # Note: will likely choke on filenames containing spaces
    searchDir=($(bash -c "echo $searchDir"))
    # note: regex matches entire path, not just filename
    # note: never include conn-summary files and always return a success exit code
    IFS=$'\n' logFiles=($(find "${searchDir[@]}" -regextype egrep -iregex ".*/${logType}(\b|_).*\.log$" | grep -v conn-summary | sort || true))
    IFS=$'\n' zipFiles=($(find "${searchDir[@]}" -regextype egrep -iregex ".*/${logType}(\b|_).*\.log\.gz$" | grep -v conn-summary | sort || true))
    files=("${logFiles[@]}" "${zipFiles[@]}")
    
    # if no log files are found then exit
    if isEmpty "$files"; then
        error "Not reading from STDIN and no log files found."
        exit 1
    fi
fi

# cache is an experimental feature
if isEmpty $EXPERIMENTAL; then
    useCache=false
fi

# can't write to cache directory; disable
if [[ ! -w $cacheDir ]]; then
    useCache=false
# only use the cache if --no-cache wasn't specified and there are files to search (not stdin)
elif $useCache && isNotEmpty $files; then
    useCache=true
else
    useCache=false
fi

# convert all terms to regexes
for term in "${terms[@]}"; do
    # if regex flag was not given then escape the search term
    if $escape; then
        term="$(escapeTerm "$term" "$termPrefix" "$termSuffix")"
    fi
    regexes+=("$term")
done

if [[ ${#regexes[@]} -eq 0 ]]; then
    # if there are no regexes to search then treat it like cat
    # TODO test files with spaces
    filterCmd="zcat --force --quiet ${files[@]}"
    # skip the cache in this case
    useCache=false
else
    invertFlag=""
    headerFlag="-e '^#'"
    if $invert; then
        invertFlag="--invert-match"
        headerFlag=""
    fi
    if $onlyFilenames; then
        # when filenames are being printed we don't want to match the header
        headerFlag=""
    fi

    # TODO: Test if you can have too many files passed in. Might have to pipe from find directly.
    filterCmd=""
    isFirstSearch=true
    parallel="xargs -n 1 -P $(nproc)"
    # loop through all search terms
    for regex in "${regexes[@]}"; do 
        # ugrep --bool needs special treatment of spaces and quotes
        regex="$(printf "%s" "$regex" | sed -e 's/ /\\x20/g' -e 's/"/\\x22/g')"
        # special case the first search regex
        if $isFirstSearch; then
            filterCmd="ug ${extra_args[@]} --binary-files=without-match --no-filename --decompress $invertFlag --bool '${headerFlag:+^# OR }($regex"
            isFirstSearch=false
        else
            if [ "$condition" = "and" ]; then
                filterCmd="$filterCmd AND $regex"
            elif [ "$condition" = "or" ]; then
                filterCmd="$filterCmd OR $regex"
            fi
        fi
    done
    filterCmd="$filterCmd)' ${files[@]}"
    # TODO test files with spaces
fi

if $useCache; then
    # create a hash of the command for caching
    uniqueHash=$(echo $filterCmd | md5sum | cut -d' ' -f1)
    cacheFile=$cacheDir/filter-cache-$uniqueHash
    # clean up expired cache entries
    find "$cacheDir" -name "filter-cache-*" -mmin "$cacheExpiry" -delete

    if [[ -e $cacheFile ]]; then
        # cache exists; just output it
        filterCmd="cat $cacheFile"
    else
        # cache doesn't exist; save one
        filterCmd="$filterCmd | tee $cacheFile"
        # remove the cache file if filter stops prematurely
        trap "rm -f '$cacheFile'" INT
    fi
    # TODO what to do if we run out of space for the cache
fi

# if stdout is not redirected, get rid of zeek headers
if ! isStdoutRedir; then
    # only do this if printing to stdout to avoid a performance hit anywhere else
    # printing to stdout implies user expects few results and isn't going to use
    # the results anywhere that would need the zeek headers
    filterCmd="$filterCmd | grep -v '^#'"
fi

if $dryRun; then
    printf "%s\n" "$filterCmd"
else
    eval $filterCmd
fi


# TODO
# run through ShellCheck

# can I use the --glob builtin for grep instead of find? 

# Other useful presets
# Multicast 224.0.0.0/4, ff00::/8

# loopback 0.0.0.0/32, 127.0.0.0/8, ::1/128

# Carrier 100.64.0.0/10
# Address:   100.64.0.0           01100100.01 000000.00000000.00000000
# Broadcast: 100.127.255.255      01100100.01 111111.11111111.11111111

# local_orig & local_resp
# ipv4, ipv6, possibly with -o to extract IPs from files
# ipv4cidr, ipv6cidr
# look at pre-existing groks https://github.com/hpcugent/logstash-patterns/blob/aaede7a2e508c1a37816bff9d9824772f1eed78d/files/grok-patterns#L29-L30
# reserved ranges that includes all non-public
# https://stackoverflow.com/a/33618635
# https://github.com/activecm/rita/blob/master/etc/rita.yaml#L67-L74

# --csv|--header|--keep-lines=1 to pass through header line for csv/tsv logs
# without ^# to search for this gets back into the original problem
# could have sed prepend #, grep to include # and then sed to remove it again at the end
# Use /dev/shm for buffering and compare for performance; Also figure out how to stream output and fail early on | head; trap SIGPIPE
# Or use read like chop does.

# use \Q and \E instead of escaping periods
# grep -P, rg -P, ug, or ug -P support this
# There are still problems with []. e.g. ["] or [ ]. Can't escape these characters in brackets and ugrep will puke.

# remove commented lines from -f file

# flag to exclude # lines
